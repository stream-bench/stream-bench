{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "ds_path = \"appier-ai-research/StreamBench\"\n",
    "ds_name = \"ds_1000\"\n",
    "\n",
    "ds1 = datasets.load_dataset(ds_path, ds_name)\n",
    "\n",
    "ds_path = \"xlangai/DS-1000\"\n",
    "ds2 = datasets.load_dataset(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_ids = [693, 695, 691, 688, 690, 694, 680, 692, 681, 689]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for row in ds1[\"test\"]:\n",
    "    if \"tensorflow\" in row[\"code_context\"]:\n",
    "        print(len(re.findall(\"copy.deepcopy\", row[\"code_context\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 379\n",
    "row = ds1[\"test\"][idx]\n",
    "print(row[\"code_context\"])\n",
    "print(\"=====\")\n",
    "print(row[\"reference_code\"])\n",
    "\n",
    "# print(row[\"code_context\"].replace(\"[insert]\", row[\"reference_code\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"appier-ai-research/robust-finetuning\"\n",
    "dataset_name = \"gsm8k\"\n",
    "\n",
    "gsm8k = load_dataset(dataset_path, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "import os\n",
    "from pathlib import Path\n",
    "from stream_bench.llms.oai_chat import OpenAIChat\n",
    "\n",
    "os.environ.update({\"OAI_KEY\": Path(\"../apikeys/openai_finetune.txt\").read_text().strip()})\n",
    "llm = OpenAIChat(model_name=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gsm8k[\"test\"][\"answer\"])):\n",
    "    a = gsm8k[\"test\"][\"answer\"][i]\n",
    "    a = ''.join(a.split(\"####\")[1].strip().split(','))\n",
    "    if int(a) < 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1113\n",
    "q = gsm8k[\"test\"][\"question\"][idx]\n",
    "print(q)\n",
    "print(gsm8k[\"test\"][\"answer\"][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\\n",
    "The following text is an LLM's response to a math question:\n",
    "\n",
    "Text (enclosed in triple quotes): '''{text}'''\n",
    "\n",
    "Extract the answer from the text (only extract the digits, potentially the sign if the number is negative), and provide it in the following JSON format:\n",
    "{{\"answer\": \"<digits>\"}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_res, _ = llm(prompt=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extract = \"\"\"\\\n",
    "The following text is an LLM's response to a math question:\n",
    "\n",
    "Text (enclosed in triple quotes): '''{text}'''\n",
    "\n",
    "Extract the answer from the text (only extract the digits, potentially the sign if the number is negative), and provide it in the following JSON format:\n",
    "{{\"answer\": \"<digits>\"}}\"\"\"\n",
    "\n",
    "prompt = prompt_extract.format(text=raw_res)\n",
    "res, _ = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from stream_bench.benchmarks.utils import extract_json_string\n",
    "\n",
    "extract_json_string(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream_bench.benchmarks.utils import strip_all_lines\n",
    "\n",
    "def get_prompt() -> str:\n",
    "    prompt_extract = strip_all_lines(\"\"\"\\\n",
    "    The following text is an LLM's response to a math question:\n",
    "\n",
    "    Text (enclosed in triple quotes): '''{text}'''\n",
    "\n",
    "    Extract the answer from the text (only extract the digits, potentially the sign if the number is negative), and provide it in the following JSON format:\n",
    "    {{\"answer\": \"<digits>\"}}\"\"\")\n",
    "    return prompt_extract.format(text=\"text\")\n",
    "\n",
    "print(get_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "path = \"appier-ai-research/robust-finetuning\"\n",
    "name = \"math\"\n",
    "\n",
    "math = load_dataset(path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "q = math[\"test\"][\"problem\"][idx]\n",
    "a = math[\"test\"][\"solution\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q)\n",
    "print()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer_from_boxed(s: str) -> str:\n",
    "    \"\"\"Extract the answer enclosed as follows: boxed{<answer>}\"\"\"\n",
    "    found = re.findall(r\"boxed\\{(.+)\\}\", s)\n",
    "    if len(found) == 1:\n",
    "        answer = found[0]\n",
    "    else:\n",
    "        print(f\"Found {len(found)} boxed answers in the string: {s}\")\n",
    "        answer = None\n",
    "    return answer\n",
    "\n",
    "for row in math[\"test\"][\"solution\"]:\n",
    "    answer = extract_answer_from_boxed(row)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Degeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "rows = list()\n",
    "with open(\"./log/gsm8k/test/ZeroShotAgent__openai__ft:gpt-4o-mini-2024-07-18:ai-research:gsm8k-100-gt:9u8sLy5N.jsonl\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        if row[\"num_output_tokens\"] == 2048:\n",
    "            rows.append(row[\"output_pred\"])\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rows[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stream_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
