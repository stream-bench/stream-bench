{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Notebook for Understanding StreamBench\n",
    "This is a step-by-step walkthrough about how to run StreamBench\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from stream_bench.agents import load_agent\n",
    "from stream_bench.benchmarks import load_benchmark\n",
    "\n",
    "# Set your API keys here\n",
    "os.environ.update({\n",
    "    \"OAI_KEY\": Path(\"../apikeys/openai_bench.txt\").read_text().strip()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Agent and Benchmark Configurations\n",
    "They are normally specified in `./configs/agent/<agent_name>.yml` and `./configs/bench/<dataset_name>.yml`. We use python dictionaries in this notebook instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot agent\n",
    "agent_cfg = {\n",
    "    \"agent_name\": \"zeroshot\",\n",
    "    \"llm\": {\n",
    "        \"series\": \"openai\",  # Remember to set the environment variable \"OAI_KEY\"\n",
    "        \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 512\n",
    "    }\n",
    "}\n",
    "# BIRD benchmark\n",
    "bench_cfg = {\n",
    "    \"bench_name\": \"bird\",\n",
    "    \"split\": \"test\",\n",
    "    \"feedback\": \"correctness\",\n",
    "    \"seed\": 42,\n",
    "    \"db_path\": \"./data/bird/dev_databases\"\n",
    "}\n",
    "# Let agent holds benchmark information\n",
    "agent_cfg[\"bench_name\"] = bench_cfg[\"bench_name\"]\n",
    "agent_cfg[\"split\"] = bench_cfg[\"split\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Agent and Benchmark Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DB schema prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534/1534 [00:00<00:00, 25510.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 found!\n",
      "Building few-shot examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent = load_agent(agent_cfg[\"agent_name\"])(agent_cfg)\n",
    "bench = load_benchmark(bench_cfg[\"bench_name\"])(**bench_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Happens at Each Time Step in the Input-Feedback Sequence?\n",
    "The steps below show the intermediate outputs at each iteration in the main script `./stream_bench/pipelines/run_bench.py` line 83-114."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 0\n",
      "Row: {'db_id': 'card_games', 'question': 'What is the language of the card with the multiverse number 149934?', 'evidence': 'multiverse number 149934 refers to multiverseid = 149934;', 'SQL': 'SELECT language FROM foreign_data WHERE multiverseid = 149934', 'question_id': 422, 'difficulty': 'simple'}\n"
     ]
    }
   ],
   "source": [
    "# Each row is the data instance for a time step\n",
    "for time_step, row in enumerate(bench.get_dataset()):\n",
    "    break\n",
    "\n",
    "print(f\"Time step: {time_step}\")\n",
    "print(f\"Row: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (only shows the keys): dict_keys(['question', 'fewshot_template', 'prompt_zeroshot', 'prompt_fewshot', 'prompt_cot', 'feedback_template', 'refine_template'])\n",
      "Model raw output: ```sql\n",
      "SELECT foreign_data.language\n",
      "FROM foreign_data\n",
      "JOIN cards ON foreign_data.uuid = cards.uuid\n",
      "WHERE cards.multiverseId = 149934;\n",
      "```\n",
      "Post-processed model output: SELECT foreign_data.language\n",
      "FROM foreign_data\n",
      "JOIN cards ON foreign_data.uuid = cards.uuid\n",
      "WHERE cards.multiverseId = 149934;\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "x = bench.get_input(row)\n",
    "model_raw_output = agent(**x)\n",
    "prediction = bench.postprocess_generation(model_raw_output, time_step)\n",
    "print(f\"Model input (only shows the keys): {x.keys()}\")\n",
    "print(f\"Model raw output: {model_raw_output}\")\n",
    "print(f\"Post-processed model output: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: {'SQL': 'SELECT language FROM foreign_data WHERE multiverseid = 149934', 'db_id': 'card_games', 'label': 'SELECT language FROM foreign_data WHERE multiverseid = 149934'}\n",
      "Prediction result: {'result': 'Answer is NOT Correct', 'correct': 0, 'n_correct': 0, 'rolling_acc': 0.0}\n",
      "Feedback: {'question': 'What is the language of the card with the multiverse number 149934?', 'self_output': 'SELECT foreign_data.language\\nFROM foreign_data\\nJOIN cards ON foreign_data.uuid = cards.uuid\\nWHERE cards.multiverseId = 149934;', 'is_correct': 0, 'ground_truth': 'SELECT language FROM foreign_data WHERE multiverseid = 149934', 'shot_template': 'Question: {question}\\n{answer}', 'memprompt_template': 'Question: {question}\\nYour SQL code: {answer}\\nUser Feedback: {correctness}'}\n"
     ]
    }
   ],
   "source": [
    "# Get feedback\n",
    "label = bench.get_output(row)\n",
    "pred_res = bench.process_results(  # prediction result: correctness of the model output\n",
    "    prediction,\n",
    "    label,  # In Text-to-SQL tasks, the SQL execution result of \"prediction\" and \"label\" are compared\n",
    "    return_details=True,\n",
    "    time_step=time_step\n",
    ")\n",
    "has_feedback, feedback = bench.give_feedback(model_raw_output, row, pred_res)\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Prediction result: {pred_res}\")\n",
    "print(f\"Feedback: {feedback}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has the agent updated itself? False\n"
     ]
    }
   ],
   "source": [
    "# The agent update itself based on the feedback\n",
    "has_update = agent.update(has_feedback, **feedback)\n",
    "print(f\"Has the agent updated itself? {has_update}\")  # Zero-shot agent: no updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stream_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
