rows = [
    {"reference_code": "def g(df):\n    return df.groupby('Item', as_index=False)['Quantity'].sum().rename(columns={'Quantity': 'Total Quantity'})\nresult = g(df.copy())", "prompt": "Problem:\nI need to group a DataFrame by one column and sum another column within each group. For example, consider the following DataFrame:\n    Item  Quantity  Price\n0   Apple      10     2\n1   Banana     15     1\n2   Apple      20     2\n3   Orange     10     3\n4   Banana     5      1\n5   Orange     15     3\n\nI want to group by 'Item' and sum the 'Quantity' for each group, resulting in:\n    Item  Total Quantity\n0   Apple  30\n1   Banana 20\n2   Orange 25\n\nHow can I achieve this using pandas?\n\nA:\n<code>\nimport pandas as pd\n\ndf = pd.DataFrame({'Item': ['Apple', 'Banana', 'Apple', 'Orange', 'Banana', 'Orange'],\n                   'Quantity': [10, 15, 20, 10, 5, 15],\n                   'Price': [2, 1, 2, 3, 1, 3]})\n</code>\nresult = ... # put solution in this variable\nBEGIN SOLUTION\n<code>", "code_context": "import pandas as pd\nimport numpy as np\nimport copy\n\n\ndef generate_test_case(test_case_id):\n    def generate_ans(data):\n        df = data\n        grouped_df = df.groupby('Item')['Quantity'].sum().reset_index()\n        grouped_df.columns = ['Item', 'Total Quantity']\n        return grouped_df\n    def define_test_input(test_case_id):\n        if test_case_id == 1:\n            df = pd.DataFrame({'Item': ['Fiction', 'Non-Fiction', 'Fiction', 'Sci-Fi', 'Non-Fiction', 'Sci-Fi'],\n                                'Quantity': [500, 300, 700, 200, 400, 300],\n                                'Price': [15, 20, 15, 25, 20, 25]})\n        if test_case_id == 2:\n            df = pd.DataFrame({'Item': ['Kiwi', 'Lemon', 'Kiwi', 'Lemon', 'Kiwi', 'Lemon'],\n                                'Quantity': [3, 4, 6, 5, 9, 7],\n                                'Price': [2, 1, 2, 1, 2, 1]})\n        if test_case_id == 3:\n            df = pd.DataFrame({'Item': ['Laptop', 'Smartphone', 'Laptop', 'Tablet', 'Smartphone', 'Tablet'],\n                                'Quantity': [100, 200, 150, 300, 250, 400],\n                                'Price': [1000, 800, 1000, 600, 800, 600]})\n        return df\n    test_input = define_test_input(test_case_id)\n    expected_result = generate_ans(copy.deepcopy(test_input))\n    return test_input, expected_result\n\n\ndef exec_test(result, ans):\n    try:\n        pd.testing.assert_frame_equal(result, ans, check_dtype=False)\n        return 1\n    except:\n        return 0\n\n\nexec_context = r\"\"\"\nimport pandas as pd\nimport numpy as np\ndf = test_input\n[insert]\n\"\"\"\n\n\ndef test_execution(solution: str):\n    code = exec_context.replace(\"[insert]\", solution)\n    for i in range(3):\n        test_input, expected_result = generate_test_case(i + 1)\n        test_env = {\"test_input\": test_input}\n        exec(code, test_env)\n        assert exec_test(test_env[\"result\"], expected_result)\n"},
    {"reference_code": "def moving_average(data, window_size):\n    n = len(data)  # length of the input data array\n    if window_size > n:\n        return np.array([])  # return empty array if window size is larger than the array\n    moving_avg = np.zeros(n - window_size + 1)  # initialize the result array\n    # Calculate initial window sum\n    window_sum = sum(data[:window_size])\n    moving_avg[0] = window_sum / window_size\n    # Iterate over the data to compute the moving average\n    for i in range(1, n - window_size + 1):\n        window_sum = window_sum - data[i - 1] + data[i + window_size - 1]\n        moving_avg[i] = window_sum / window_size\n    return moving_avg\nB = moving_average(A, window_size)", "prompt": "Problem:\nHow can I calculate the moving average of a numpy array over a specified window size? For instance, if I have an array like this:\n> import numpy as np\n> data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n> window_size = 3\nI want to compute the moving average such that the output is:\narray([2, 3, 4, 5, 6, 7, 8, 9])\nEach element of the output array is the average of the current and the previous two elements from the input array.\n\nA:\n<code>\nimport numpy as np\ndata = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nwindow_size = 3\n</code>\n# implement the solution in this function\nB = moving_average(data, window_size)\nBEGIN SOLUTION\n<code>", "code_context": "import numpy as np\nimport pandas as pd\nimport copy\n\n\ndef generate_test_case(test_case_id):\n    def define_test_input(test_case_id):\n        if test_case_id == 1:\n            A = np.array([1, 2, 3, 4, 5, 6, 7])\n            window_size = 2\n        elif test_case_id == 2:\n            np.random.seed(42)\n            A = np.random.rand(23)\n            window_size = 5\n        return A, window_size\n\n    def generate_ans(data):\n        arr, window_size = data\n        moving_avg = np.zeros(len(arr) - window_size + 1)\n        for i in range(len(arr) - window_size + 1):\n            moving_avg[i] = np.sum(arr[i:i+window_size]) / window_size\n        return moving_avg\n\n    test_input = define_test_input(test_case_id)\n    expected_result = generate_ans(copy.deepcopy(test_input))\n    return test_input, expected_result\n\n\ndef exec_test(result, ans):\n    np.testing.assert_allclose(result, ans)\n    return 1\n\n\nexec_context = r\"\"\"\nimport numpy as np\nA, window_size = test_input\n[insert]\nresult = B\n\"\"\"\n\n\ndef test_execution(solution: str):\n    code = exec_context.replace(\"[insert]\", solution)\n    for i in range(2):\n        test_input, expected_result = generate_test_case(i + 1)\n        test_env = {\"test_input\": test_input}\n        exec(code, test_env)\n        assert exec_test(test_env[\"result\"], expected_result)\n"},
    {"reference_code": "documents_train, documents_test, labels_train, labels_test = train_test_split(\n    documents, labels, test_size=0.3, stratify=labels, random_state=42\n)\nresult = (labels_train, labels_test)", "prompt": "Problem:\nI am working on a natural language processing project where I need to categorize text documents based on their topics. For this purpose, I want to use the `sklearn.model_selection.train_test_split` to divide my dataset into training and testing sets. Here is my dataset (a list of text documents):\ndocuments = [\n    \"Machine learning is fascinating.\",\n    \"Artificial intelligence and machine learning are closely related fields.\",\n    \"Natural language processing is a part of artificial intelligence.\",\n    \"Python is a great programming language for machine learning.\",\n    \"Deep learning is a subset of machine learning.\",\n    \"Support vector machines are a type of machine learning algorithm.\",\n    \"There are various techniques in artificial intelligence.\",\n    \"Python is widely used in data science.\",\n    \"Unsupervised learning involves clustering and association.\",\n    \"Machine learning can be supervised or unsupervised.\"\n]\nI understand that the `train_test_split` function from `sklearn.model_selection` can be used to achieve this, but I want to ensure that the split is stratified based on the topics in my dataset. Assume I have corresponding labels for the documents indicating their topics:\nlabels = [\"ML\", \"AI\", \"NLP\", \"ML\", \"ML\", \"ML\", \"AI\", \"DS\", \"ML\", \"ML\"]\n\nCan you show me how to do this split, ensuring that the training and testing sets are stratified based on the given labels?\n<code>\ndocuments = [\n    ...\n]\nlabels = [ ...]\n</code>\nYou should split the data by 7:3 split between train and test\nBEGIN SOLUTION\n<code>", "code_context": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nimport copy\n\ndef generate_test_case(test_case_id):\n    def define_test_input(test_case_id):\n        if test_case_id == 1:\n            documents = [\n                \"Machine learning is fascinating.\",\n                \"Artificial intelligence and machine learning are closely related fields.\",\n                \"Natural language processing is a part of artificial intelligence.\",\n                \"Python is a great programming language for machine learning.\",\n                \"Deep learning is a subset of machine learning.\",\n                \"Support vector machines are a type of machine learning algorithm.\",\n                \"There are various techniques in artificial intelligence.\",\n                \"Python is widely used in data science.\",\n                \"Unsupervised learning involves clustering and association.\",\n                \"Machine learning can be supervised or unsupervised.\",\n                \"Another document about machine learning.\",\n                \"Yet another document about artificial intelligence.\"\n            ]\n            labels = [\"ML\", \"AI\", \"NLP\", \"DS\", \"ML\", \"NLP\", \"AI\", \"DS\", \"ML\", \"ML\", \"ML\", \"AI\"]\n        elif test_case_id == 2:\n            documents = [\n                \"Document 1 about topic A.\",\n                \"Document 2 about topic B.\",\n                \"Document 3 about topic A.\",\n                \"Document 4 about topic B.\",\n                \"Document 5 about topic A.\",\n                \"Document 6 about topic B.\",\n                \"Document 7 about topic A.\",\n                \"Document 8 about topic B.\",\n                \"Document 9 about topic A.\",\n                \"Document 10 about topic B.\",\n                \"Document 11 about topic A.\",\n                \"Document 12 about topic B.\"\n            ]\n            labels = [\"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\"]\n        return documents, labels\n\n    def generate_ans(data):\n        documents, labels = data\n        _, _, labels_train, labels_test = train_test_split(\n            documents, labels, test_size=0.3, stratify=labels, random_state=42\n        )\n        return labels_train, labels_test\n\n    test_input = define_test_input(test_case_id)\n    expected_result = generate_ans(test_input)\n    return test_input, expected_result\n\ndef exec_test(result, ans):\n    labels_train, labels_test = result\n    expected_labels_train, expected_labels_test = ans\n    np.testing.assert_array_equal(labels_train, expected_labels_train)\n    np.testing.assert_array_equal(labels_test, expected_labels_test)\n    return 1\n\nexec_context = r\"\"\"\nfrom sklearn.model_selection import train_test_split\ndocuments, labels = test_input\n[insert]\nresult = (labels_train, labels_test)\n\"\"\"\n\ndef test_execution(solution: str):\n    code = exec_context.replace(\"[insert]\", solution)\n    for i in range(2):\n        test_input, expected_result = generate_test_case(i + 1)\n        test_env = {\"test_input\": test_input}\n        exec(code, test_env)\n        assert exec_test(test_env[\"result\"], expected_result)\n"},
    {"reference_code": "def calculate_mean_max_values(tensor):\n    # Extract the maximum values from each row\n    max_values = tf.reduce_max(tensor, axis=1)\n    # Calculate the mean of these maximum values\n    mean_max = tf.reduce_mean(max_values)\n    return mean_max\nB = calculate_mean_max_values(tensor)", "prompt": "Problem:\nI'm using tensorflow 2.10.0 and I need to create a function that calculates the mean of the maximum values from each row in a tensor. For instance, if the tensor is as follows:\ntensor = tf.Tensor(\n    [[0.5, 0.2, 0.9],\n     [0.1, 0.3, 0.4],\n     [0.7, 0.8, 0.6]]\n)\nThe function should calculate the maximum value from each row, which are 0.9, 0.4, and 0.8 respectively, and then compute the mean of these maximum values. The expected result would be (0.9 + 0.4 + 0.8) / 3 = 0.7.\nHow can I implement this function using TensorFlow?\n\n<code>\ntensor = tf.Tensor(\n    [[0.5, 0.2, 0.9],\n     [0.1, 0.3, 0.4],\n     [0.7, 0.8, 0.6]]\n)\n</code>\n# Implement your function which takes in tensor and output the answer with execution included:\nB = your_function(tensor)\n<code>", "code_context": "import numpy as np\nimport tensorflow as tf\nimport copy\n\ndef generate_test_case(test_case_id):\n    def define_test_input(test_case_id):\n        if test_case_id == 1:\n            tensor = tf.constant(\n                [[0.5, 0.2, 0.9],\n                 [0.1, 0.3, 0.4],\n                 [0.7, 0.8, 0.6]]\n            )\n        elif test_case_id == 2:\n            np.random.seed(42)\n            tensor = tf.constant(np.random.rand(5, 10))\n        return tensor\n\n    def generate_ans(data):\n        tensor = data\n        max_values = tf.reduce_max(tensor, axis=1)\n        mean_max = tf.reduce_mean(max_values)\n        return mean_max.numpy()\n\n    test_input = define_test_input(test_case_id)\n    expected_result = generate_ans(copy.deepcopy(test_input))\n    return test_input, expected_result\n\ndef exec_test(result, ans):\n    np.testing.assert_allclose(result, ans)\n    return 1\n\nexec_context = r\"\"\"\nimport tensorflow as tf\ntensor = test_input\n[insert]\nresult = B.numpy()\n\"\"\"\n\ndef test_execution(solution: str):\n    code = exec_context.replace(\"[insert]\", solution)\n    for i in range(2):\n        test_input, expected_result = generate_test_case(i + 1)\n        test_env = {\"test_input\": test_input}\n        exec(code, test_env)\n        assert exec_test(test_env[\"result\"], expected_result)"}
]